#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Aug 29 13:39:55 2017

@author: m75380

Add extend sorted keys

Add option to label full file (no inference on unlabelled)

multiple query

security 

Discrepancy btw labelling (worse) and matching (better)

Problem with precision when no match found during labelling

--> add (source_id, None) to pairs when none are found

"""

import numpy as np
import pandas as pd

from .helpers import _bulk_search



def _is_match(resp, thresh):
    '''Return whether of not the response has hits and best result has a score
    above `thresh`.
    '''
    return bool(resp['hits']['hits']) and (resp['hits']['max_score'] >= thresh)

def _has_hits(resp):
    return bool(resp['hits']['hits'])

def _first_match(list_of_responses, list_of_thresholds):
    '''Return the first real match (above threshold) and if not return the first 
    non empty result if possible. 
    
    Parameters
    ----------
        list_of_responses: list 
        list_of_thresholds: list
    '''
    assert len(list_of_responses) == len(list_of_thresholds)
    for i, (resp, thresh) in enumerate(zip(list_of_responses, list_of_thresholds)):
        if _is_match(resp, thresh):
            return i, resp
    for i, resp in enumerate(list_of_responses):
        if _has_hits(resp):
            return i, resp
    return 0, list_of_responses[0]
            

def _bulk_search_to_full_response(res_of_bulk_search, list_of_thresholds):
    '''
    Takes the output _bulk_search and transforms it to associate a single result
    per row.
    
    Applies `_first_match` to the list of results for each row. This is meant
    to be used in es_linker.
    
    
    Parameters
    ----------
    full_responses: list of Elasticsearch responses
        Flat list of results for search for rows x query_templates.
        Ex: [res_row1_qA, res_row1_qB, res_row2_qA, res_row2_qB, ...]
    list_of_thresholds: list of float
        Thresholds associated to each query.
    
    Returns
    -------
    new_full_responses: list of Elasticsearch responses
        List of responses with the best response for each row, with the same 
        number of items as original rows.
    '''
    
    num_rows_source = int(len(res_of_bulk_search) / len(list_of_thresholds))
    assert len(res_of_bulk_search) % num_rows_source == 0
    
    res_of_bulk_search = [res_of_bulk_search[i] for i in range(len(res_of_bulk_search))] # Don't use items to preserve order
    return [_first_match(res_of_bulk_search[n::num_rows_source], list_of_thresholds) \
                      for n in range(0, num_rows_source)]

def es_linker(es, source, params):
    '''Link source to reference following instructions in params and return the
    concatenation of source and reference with the matches found.
    
    Parameters
    ----------
    source: instance of `pandas.DataFrame`
        The table containing data of the source (dirty data).
    params: dict
        The params dictionnary can be generated by `export_best_params` in the 
        `Labeler`. 
        
        Expected fields are:
            es: instance of `Elasticsearch`
            index_name: str
                name of the Elasticsearch index to fetch from
            queries: list of dicts describing queries.
                The query templates to use to perform matching. Their order determins
                the priority.
            must: dict (optional)
                Terms to filter by field (AND: will include ONLY IF ALL are in text).
            must_not: dict (optional)
                Terms to exclude by field from search (OR: will exclude if ANY is found).
            exact_pairs: list of tuples
                list of (source_id, ES_ref_id) which are certain matches.
                
    Returns
    -------
    new_source: instance of `pandas.DataFrame`
        The result of matching. A DataFrame with the same number of rows as 
        `source` which is the concatenation of `source` and of the matches found 
        in the reference table.
    '''
    
    index_name = params['index_name']
    queries = params['queries'] # queries is {'template': ..., 'threshold':...}
    must_filters = params.get('must', {})
    must_not_filters = params.get('must_not', {})
    exact_pairs = params.get('exact_pairs', [])
    non_matching_pairs = params.get('non_matching_pairs', [])
    
    exact_source_indices = [x[0] for x in exact_pairs if x[1] is not None if x[0] in source.index]
    exact_ref_indices = [x[1] for x in exact_pairs if x[1] is not None if x[0] in source.index]
    source_indices = [x[0] for x in source.iterrows() if x [0] not in exact_source_indices]
    
    # Perform matching on non-exact pairs (not labelled)
    if source_indices:
        rows = (x[1] for x in source.iterrows() if x[0] in source_indices)
        
        all_search_templates, res_of_bulk_search = _bulk_search(es, index_name, 
                    [q['template'] for q in queries], rows, must_filters, must_not_filters, num_results=1)
        full_responses = _bulk_search_to_full_response(res_of_bulk_search, [q['thresh'] for q in queries])
        del res_of_bulk_search

        matches_in_ref = pd.DataFrame([resp['hits']['hits'][0]['_source'] \
                                   if _has_hits(resp) \
                                   else {} \
                                   for _, resp in full_responses], index=source_indices)
                        
        ref_id = pd.Series([resp['hits']['hits'][0]['_id'] \
                                if _has_hits(resp) \
                                else np.nan \
                                for _, resp in full_responses], index=matches_in_ref.index)
    
        confidence = pd.Series([resp['hits']['hits'][0]['_score'] \
                                if _has_hits(resp) \
                                else np.nan \
                                for _, resp in full_responses], index=matches_in_ref.index)
        
        threshold = pd.Series([queries[i]['thresh'] \
                                for i, _ in full_responses], index=matches_in_ref.index)

        matches_in_ref.columns = [x + '__REF' for x in matches_in_ref.columns]
        matches_in_ref['__IS_MATCH'] = confidence >= threshold
        matches_in_ref['__ID_REF'] = ref_id
        matches_in_ref['__CONFIDENCE'] = confidence    
        matches_in_ref['__THRESH'] = threshold
        
        # TODO: confidence_gap makes no sense with multiple queries
        #        confidence_gap = pd.Series([resp['hits']['hits'][0]['_score'] - resp['hits']['hits'][1]['_score']
        #                                if (len(resp['hits']['hits']) >= 2) and _has_hits(resp) \
        #                                else np.nan \
        #                                for i, resp in full_responses], index=matches_in_ref.index)        
        #        matches_in_ref['__GAP'] = confidence_gap
        #        matches_in_ref['__GAP_RATIO'] = confidence_gap / confidence
        
        # Put confidence to zero for user labelled negative pairs
        sel = [x in non_matching_pairs for x in zip(source_indices, matches_in_ref.__ID_REF)]
        for col in ['__CONFIDENCE']: #, '__GAP', '__GAP_RATIO']:
            matches_in_ref.loc[sel, '__CONFIDENCE'] = 0
        
    else:
        matches_in_ref = pd.DataFrame()
    
    # Perform matching exact (labelled) pairs
    if exact_ref_indices:
        full_responses = [es.get(index_name, ref_idx) for ref_idx in exact_ref_indices]
        exact_matches_in_ref = pd.DataFrame([resp['_source'] for resp in full_responses], 
                                            index=exact_source_indices)
        exact_matches_in_ref.columns = [x + '__REF' for x in exact_matches_in_ref.columns]
        exact_matches_in_ref['__ID_REF'] = exact_ref_indices
        exact_matches_in_ref['__CONFIDENCE'] = 999
        
    else:
        exact_matches_in_ref = pd.DataFrame()
    
    #
    assert len(exact_matches_in_ref) + len(matches_in_ref) == len(source)
    new_source = pd.concat([source, pd.concat([matches_in_ref, exact_matches_in_ref])], 1)        
    
    return new_source


    

        
